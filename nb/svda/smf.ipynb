{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4423297-7c6a-415b-b3d9-e30fa09a80a4",
   "metadata": {},
   "source": [
    "$$\\log p(\\phi | \\{x_i\\}) \\approx \\prod\\limits_{i=1}^N \\frac{1}{S_i} \\sum\\limits_{j=1}^{S_i} p(\\theta_{ij} | \\phi)$$\n",
    "\n",
    "For normalizing flows \n",
    "$$p(\\theta_{ij} | \\phi) = q_\\phi(\\theta_{ij})$$\n",
    "\n",
    "Then a MAP solution for $\\phi$ can be obtained by maximizing $\\log p(\\phi | \\{ x_i \\})$, which is equivalent to maximizing\n",
    "$$\\sum_{i=1}^N \\log \\sum\\limits_{j=1}^S q_\\phi(\\theta_{ij})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae0cfff-d41c-40c8-ba76-a7b9652df31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py \n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce04eb8-8555-410e-b933-bfa1a79d1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nflows import transforms, distributions, flows\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.distributions as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06eb997-3dfa-45b7-8a3e-b5d742013277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- plotting -- \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.xmargin'] = 1\n",
    "mpl.rcParams['xtick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['xtick.major.size'] = 5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['ytick.major.size'] = 5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['legend.frameon'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd90248-edb2-48ac-89be-283b9fdfef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir = '/global/cfs/cdirs/desi/users/chahah/provabgs/svda/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c351bf1-3eee-4848-8fb8-cdc70d153997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11b7bd-a54d-471f-9069-e11951977292",
   "metadata": {},
   "source": [
    "# compile $M_*$ posterior data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b238a6f-a6ec-46c3-a3a0-1a31e5ccf88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/global/cfs/cdirs/desi/users/chahah/provabgs/svda/provabgs-sv3-bright-10154.BGS_BRIGHT.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedb911a-190d-43da-8b93-0eb891ccef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logM_posteriors = []\n",
    "for fpost in glob.glob(os.path.join(dat_dir, 'provabgs-*hdf5'))[:5]: \n",
    "    f = h5py.File(fpost, 'r')\n",
    "    mcmc = f['samples'][...][:,-100:,:,0]\n",
    "    \n",
    "    logM_posteriors.append(mcmc.reshape((mcmc.shape[0], mcmc.shape[1] * mcmc.shape[2])))\n",
    "logM_posteriors = np.concatenate(logM_posteriors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a8725e-2882-4282-b8bc-567afda3a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 12.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(logM_posteriors.shape[0]), size=100, replace=False): \n",
    "    plt.hist(logM_posteriors[i,::10], bins=40, alpha=0.5)\n",
    "plt.xlim(8., 12.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bbe49f-82f6-4cea-8749-9fd33582c0ff",
   "metadata": {},
   "source": [
    "# estimate $p(M_* | \\{x_i, z_i \\})$ using NDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f9a8c7-f81f-4f8c-bc86-9c029eceb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu' \n",
    "device = torch.device(type='cuda', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0bedd4-6732-4325-a885-677ab4d70f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/c/chahah/.conda/envs/gqp/lib/python3.7/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "NVIDIA A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA A100-SXM4-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-89022dc86310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogM_posteriors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mavg_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstd_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstd_post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_data = torch.tensor(logM_posteriors.astype(np.float32)).to(device)\n",
    "avg_post = torch.mean(x_data, axis=0)\n",
    "std_post = torch.std(x_data, axis=0)\n",
    "w_post = (x_data - avg_post)/std_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d1bd504-799d-46eb-8370-855e0bc1c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(flow, post): \n",
    "    return -torch.sum(torch.logsumexp(flow.log_prob(post.flatten()[:,None]).reshape(post.shape), axis=1) - torch.log(torch.tensor(100.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1238e3-c062-45d9-8227-a207e9d4c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7db64bb2-bc6e-425f-a7d2-f639734ff56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhidden = int(np.ceil(np.exp(np.random.uniform(np.log(64), np.log(256)))))\n",
    "\n",
    "blocks = []\n",
    "for iblock in range(5): \n",
    "    blocks += [\n",
    "        transforms.MaskedAffineAutoregressiveTransform(features=ndim, hidden_features=nhidden),\n",
    "        transforms.RandomPermutation(features=ndim)\n",
    "    ]\n",
    "\n",
    "transform = transforms.CompositeTransform(blocks)\n",
    "\n",
    "# Define a base distribution.\n",
    "base_distribution = distributions.StandardNormal(shape=[ndim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bce18ebe-a491-4bdb-af81-31388942fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 3.76e+03 \t 3.03e+03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1a7805d3b93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_post\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gqp/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gqp/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_flows = []\n",
    "\n",
    "lr = 1e-3\n",
    "num_iter = 1000\n",
    "patience = 20\n",
    "\n",
    "best_valid_losses, valid_losseses = [], []\n",
    "for i in range(1): \n",
    "    nhidden = int(np.ceil(np.exp(np.random.uniform(np.log(64), np.log(256)))))\n",
    "\n",
    "    blocks = []\n",
    "    for iblock in range(5): \n",
    "        blocks += [\n",
    "            transforms.MaskedAffineAutoregressiveTransform(features=ndim, hidden_features=nhidden),\n",
    "            transforms.RandomPermutation(features=ndim)\n",
    "        ]\n",
    "\n",
    "    transform = transforms.CompositeTransform(blocks)\n",
    "\n",
    "    # Define a base distribution.\n",
    "    base_distribution = distributions.StandardNormal(shape=[ndim])\n",
    "\n",
    "    # Combine into a flow.\n",
    "    flow = flows.Flow(transform=transform, distribution=base_distribution)\n",
    "    flow.to(device)\n",
    "\n",
    "    # parameters = [weights, means, stdevs]\n",
    "    optimizer1 = optim.Adam(flow.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer1, lr, total_steps=num_iter)\n",
    "\n",
    "    best_epoch = 0 \n",
    "    best_valid_loss = np.inf\n",
    "    valid_losses = []\n",
    "    for epoch in range(num_iter):\n",
    "        train_loss = 0.\n",
    "        for ii in range(90): \n",
    "            optimizer1.zero_grad()\n",
    "            loss = Loss(flow, w_post[:,ii::100])\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer1.step()\n",
    "        train_loss = train_loss/90.\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.\n",
    "            for ii in range(10): \n",
    "                loss = Loss(flow, w_post[:,90+ii::100])\n",
    "                valid_loss += loss.item()\n",
    "            valid_loss = valid_loss/10.            \n",
    "            valid_losses.append(valid_loss)\n",
    "            if epoch % 20 == 0: \n",
    "                print('%i \\t %.2e \\t %.2e' % (epoch, train_loss, valid_loss))\n",
    "            if valid_loss < best_valid_loss: \n",
    "                best_valid_loss = valid_loss\n",
    "                best_epoch = epoch\n",
    "            else: \n",
    "                if best_epoch < epoch - patience: \n",
    "                    print('>>>%i \\t %.5e' % (epoch, best_valid_loss))\n",
    "                    break\n",
    "                    \n",
    "        scheduler.step()\n",
    "    all_flows.append(flow)\n",
    "    valid_losseses.append(valid_losses)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa8a06-611f-4033-8826-586c5905559c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gqp",
   "language": "python",
   "name": "gqp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
